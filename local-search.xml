<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>数模心得</title>
    <link href="/2023/11/23/%E6%95%B0%E6%A8%A1%E5%BF%83%E5%BE%97/"/>
    <url>/2023/11/23/%E6%95%B0%E6%A8%A1%E5%BF%83%E5%BE%97/</url>
    
    <content type="html"><![CDATA[<center> 数模心得 </center><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在大学一共和队友参加了四次数模，从今年过年开始的MathorCup大数据，到中旬的电工杯，到万众瞩目的国赛，最后是前几天结束的数维杯。走过很多坑，也有很多收获，在这里总结一下吧。</p><p>所有的结果：<br><img src="/../pic/mathModeling/mathModeling1.png" alt="Alt text"></p><h2 id="前三次比赛的经历"><a href="#前三次比赛的经历" class="headerlink" title="前三次比赛的经历"></a>前三次比赛的经历</h2><h3 id="MathorCup大数据"><a href="#MathorCup大数据" class="headerlink" title="MathorCup大数据"></a>MathorCup大数据</h3><p>前三个比赛只有MathorCup获得了一个三等奖，另外两个属于是完全没有得奖。在第一次参加完MathorCup后我其实都没想过会得奖，里面一个小小的创新也是似对非对得，或许是运气好了点~。不过那段寒假时间和队友一起打着电话，在家里用着家里面的电视当屏幕用，躺在沙发上思考的日子还是有一点怀念，毕竟是第一次做数模也不知道怎么才能做好，一切都是属于尝试。</p><h3 id="电工杯"><a href="#电工杯" class="headerlink" title="电工杯"></a>电工杯</h3><p>到了中旬，朋友说有个电工杯，叫上我的两个好队友就去参加，那段时间是在图书馆的顶楼，我们悄悄的讨论（中间还出去吃了一次火锅，态度不太端正哈哈），最后的评价指标也是使用两个方法凑合起来整成个新方法，不过电工杯也忽略了很多细节，没有过多仔细的检查，论点也不是特别有道理，论文整体也是较为混乱的。不出意外的没了。</p><h3 id="国赛"><a href="#国赛" class="headerlink" title="国赛"></a>国赛</h3><p>为了国赛还特地的准备了一段时间，都想着在国赛的时候大展身手拿一次好的奖，大学中就可以不用再参加数学建模的比赛了。在比赛前似乎该准备的都准备了，我们选择的是B题，也就是纯数学题，没有选择大数据分析是觉得人选的太多了，而且创新起来很困难。这也是我们队第一次尝试做B题，在此之前也做过往年的题练练手，只不过做不来哈哈，折磨了很久。国赛我们是在6408做的，到了国赛那天晚上6点，我紧张的打开了题目一看，哦豁，没看懂（不过当天晚上就和队友讨论并理解了题目），当晚我们已经觉得第一问很有思路而且很简单了。以为一切都正常发展的时候，意外也就悄悄地降临。第二问花费了巨多的时间，而且由于指导老师说我们对题目理解有问题导致我们把第一问和第二问都重新花时间思考和重做了很久（最后还是改回去了），不过指导老师还是给我启发了一些思路的。</p><p>结果到前一天晚上，由于我们拖拖拉拉不断修改之前的答案，论文起笔时间夜晚，那一天晚上我们才开始做第三题。经历了一个通宵（我睡了1个小时，另一个队友只睡了半个小时），总算是有思路了，不得不说晚上的效率是真的低。第二天早上赶紧好好书写了一遍交给了写论文的同学开始誊抄，我们又开始写第四问，没想到的是第四问对我们来说有点过于困难甚至连思路都难确定，到处找找到处看看总算是混出来个像答案的东西（肯定是错的），不过已经来不及了，写论文的同学赶紧整完后，时间更是所剩无几。这个时候我们才开始写其他的摘要啊、文献什么的，由于写论文的同学前面字数不太够，我们还需要去补充字数。图片不够又到处去找图片，真的是超级混乱，在比赛前半个小时总算是像个样子了，赶紧去找老师准备好提交，当时脑子真的巨混但是特别紧张清醒。</p><p>到处再看了看也不是很仔细，最后看着只有几分钟了就赶紧提交，那天晚上才真的是赶紧我就是肖申克监狱里面的安迪他逃出监狱的赶紧（有点夸张哈哈哈），之后就回家休息了一天又来上课了。</p><p>不出意外，第二天我没事看论文的时候发现了巨大的排版错误，第一问的答案的表格居然飞到别的地方了，跟表的名字完全不对应，我就知道已经完蛋了。本来后面的问就是有点问题的，就想靠前面拿分，前面结果还发生了意外，更不要说后面图片大小不一致等一些小小的问题。</p><p>结果是不出意外的国赛没了，这次失败给了我巨大的打击，感觉自己不是做数模的料，不过真的真的需要一次证明自己！继续就拉上队友又报名了数维杯。</p><h3 id="数维杯"><a href="#数维杯" class="headerlink" title="数维杯"></a>数维杯</h3><p>又回到了6408开始这次的比赛，这次的数模可以说是这几次以来最好的一次了（选择的数据分析类题目），我们在前一天就写完了题目，用了大半天的时间和队友一点点修正论文，检查图片，检查有没有论证不清晰有问题的地方。对数学公式也较为严谨的推到过，而且代码基本上都是自己搞的，没有用统计学软件。</p><p>检查了很多问题，真的感觉完美的不能再完美了，图片我也让画图的同学画了又画，就是为了追求那完美，不能有一点点的问题出现。不过失误的是我们低估了翻译的时间，最后忙到凌晨5点提交了论文，当时脑子也不清醒，只希望翻译的没什么问题，自己也来不及去检查。最后才发现只有表格有一点点的小问题，其他都还不错的呢。</p><p>希望数维杯不要再没了，一定要证明我们队可以做好一次。</p><h2 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h2><p>如果数维杯没G，那就去写一个教程~</p>]]></content>
    
    
    <categories>
      
      <category>Experience</category>
      
    </categories>
    
    
    <tags>
      
      <tag>math modeling</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AlexNet实现</title>
    <link href="/2023/11/06/AlexNet%E5%AE%9E%E7%8E%B0/"/>
    <url>/2023/11/06/AlexNet%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<center>AlexNet实现</center><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这是在两年前接触的第一个CNN，当时也是糊里糊涂的理解。去年读过了AlexNet源论文，第一次好好推导了一遍，过后也复现了一次，不过没有好好保存，后面重装电脑无意中删掉了。</p><p>刚好要给大一学弟做培训，就打算来再做做AlexNet，也当是给之前的记录补上了。</p><h2 id="Alex-结构"><a href="#Alex-结构" class="headerlink" title="Alex 结构"></a>Alex 结构</h2><p>AlexNet结构十分简单，仅用到了卷积、池化、全连接。<br><img src="/../pic/AlexNet/AlexNet1.png" alt="Alt text"><br>卷积对尺寸的变化是W &#x3D; (W - K + 2P) &#x2F; S + 1</p><p>池化对尺寸的变化是H &#x3D; (H + K) &#x2F; S + 1</p><p><strong>第一要注意原文中使用双GPU训练，故自己跑的话图像深度缩小一半</strong></p><p>下图很好说明了参数和尺寸的变化<br><img src="/../pic/AlexNet/AlexNet2.png" alt="Alt text"></p><p><strong>第二的注意的点是原文中尺寸是227，但实际操作时应为224才是正确的</strong></p><p>接下来就可以开始准备搭建了</p><h2 id="实现AlexNet"><a href="#实现AlexNet" class="headerlink" title="实现AlexNet"></a>实现AlexNet</h2><h3 id="Create-The-Model"><a href="#Create-The-Model" class="headerlink" title="Create The Model"></a>Create The Model</h3><p>首先导入pytorch需要的库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torchsummary <span class="hljs-keyword">import</span> summary<br></code></pre></td></tr></table></figure><p>summary可选，用来输出网络</p><p>接下来开始创建AlexNet，开始根据上面的参数设置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">AlexNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes=<span class="hljs-number">2</span></span>):<br>        <span class="hljs-built_in">super</span>(AlexNet, self).__init__()<br>        self.features = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">48</span>, kernel_size=<span class="hljs-number">11</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">2</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br><br>            nn.Conv2d(<span class="hljs-number">48</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br><br>            nn.Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br><br>            nn.Conv2d(<span class="hljs-number">192</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br><br>            nn.Conv2d(<span class="hljs-number">192</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>        )<br>        self.classifier = nn.Sequential(<br>            nn.Dropout(<span class="hljs-number">0.5</span>),<br>            nn.Linear(<span class="hljs-number">128</span> * <span class="hljs-number">6</span> * <span class="hljs-number">6</span>, <span class="hljs-number">4096</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br><br>            nn.Dropout(<span class="hljs-number">0.5</span>),<br>            nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            <br>            nn.Linear(<span class="hljs-number">4096</span>, num_classes),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.features(x)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = self.classifier(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>这个类中创建两个函数</p><ul><li>在<code>__init__</code>中定义了2个属性，分别是features、classifier，用于卷积和全连接，在里面使用了nn.Sequential创建。</li><li>在forward中连接了网络结构</li></ul><p>继承了nn.Module类：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">super</span><span class="hljs-params">(AlexNet, self)</span></span>.<span class="hljs-built_in">__init__</span>()<br></code></pre></td></tr></table></figure><p>把矩阵展长成一维的：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">x</span> = torch.flatten(x, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>更具体一些相信没什么问题了，这里不过多阐述。</p><h3 id="Prepare-The-Dataset"><a href="#Prepare-The-Dataset" class="headerlink" title="Prepare The Dataset"></a>Prepare The Dataset</h3><p>包含加载数据和预处理，在dog_cat文件夹下存放有train、val文件夹，里面分别有dog、cat文件夹用于存放猫和狗图片。这里给出一个别人的百度网盘的连接可以用于下载<a href="https://pan.baidu.com/share/init?surl=UOJUi-Wm6w0D7JGQduq7Ow">百度网盘猫狗数据集下载链接</a>， 密码：485q，来自<a href="https://blog.csdn.net/weixin_45836809/article/details/121690604">csdn博客</a></p><p>下面是代码，这个写法比较整洁，当然也可以分开创建，在数据处理中并没有过多的处理，如果想要有其他的变化在<code>transforms.Compose</code>中加入就可以了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br><span class="hljs-comment"># 图片预处理</span><br>data_transforms = &#123;<br>    <span class="hljs-string">&#x27;train&#x27;</span>: transforms.Compose([<br>        transforms.RandomResizedCrop(<span class="hljs-number">224</span>),<br>        transforms.RandomHorizontalFlip(),<br>        transforms.ToTensor(),<br>        transforms.Normalize([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])<br>    ]),<br>    <span class="hljs-string">&#x27;val&#x27;</span>: transforms.Compose([<br>        transforms.Resize(<span class="hljs-number">256</span>),<br>        transforms.CenterCrop(<span class="hljs-number">224</span>),<br>        transforms.ToTensor(),<br>        transforms.Normalize([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])<br>    ]),<br>&#125;<br><br><span class="hljs-comment"># 加载数据</span><br>image_datasets = &#123;x: datasets.ImageFolder(<span class="hljs-string">&quot;/mnt/e/Dataset/dog_cat/&quot;</span>+x, data_transforms[x]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;val&#x27;</span>]&#125;<br>dataloaders = &#123;x: DataLoader(image_datasets[x], batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;val&#x27;</span>]&#125;<br></code></pre></td></tr></table></figure><p>这样写有几个好处：</p><ul><li>因为数据集的格式我们不用自定义data_loader类，当然如果不嫌麻烦也可以自己写一个</li><li>代码在使用时十分的整洁，在加载时需要指定<code> dataloaders[phase]</code>中的<code>phase</code></li></ul><p>当然如果不是很清楚其中的变量打印出来看看就明白很多了。</p><h3 id="Start-Train"><a href="#Start-Train" class="headerlink" title="Start Train"></a>Start Train</h3><p>在这里只保存了最后一次训练的结果，如果想更完善一些可以对比每一次<code>epoch</code>的精度来选择性的保存结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>num_epochs = <span class="hljs-number">5</span><br><br>model = AlexNet().to(device)<br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>)<br><br><span class="hljs-comment"># 训练模型</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-----&quot;</span>)<br>    <span class="hljs-keyword">for</span> phase <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;val&#x27;</span>]:<br>        <span class="hljs-keyword">if</span> phase == <span class="hljs-string">&#x27;train&#x27;</span>:<br>            model.train()<br>        <span class="hljs-keyword">else</span>:<br>            model.<span class="hljs-built_in">eval</span>()<br><br>        running_loss = <span class="hljs-number">0.0</span><br>        running_corrects = <span class="hljs-number">0</span><br><br>        <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> dataloaders[phase]:<br>            inputs, labels = inputs.to(device), labels.to(device)<br>            optimizer.zero_grad()<br><br>            <span class="hljs-keyword">with</span> torch.set_grad_enabled(phase == <span class="hljs-string">&#x27;train&#x27;</span>):<br>                outputs = model(inputs)<br>                _, preds = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br>                loss = criterion(outputs, labels)<br><br>                <span class="hljs-keyword">if</span> phase == <span class="hljs-string">&#x27;train&#x27;</span>:<br>                    loss.backward()<br>                    optimizer.step()<br><br>            running_loss += loss.item() * inputs.size(<span class="hljs-number">0</span>)<br>            running_corrects += torch.<span class="hljs-built_in">sum</span>(preds == labels.data)<br><br>        epoch_loss = running_loss / <span class="hljs-built_in">len</span>(image_datasets[phase])<br>        epoch_acc = running_corrects.double() / <span class="hljs-built_in">len</span>(image_datasets[phase])<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(phase, epoch_loss, epoch_acc))<br><br><span class="hljs-comment"># 保存模型</span><br>torch.save(model.state_dict(), <span class="hljs-string">&quot;model.pth&quot;</span>)<br></code></pre></td></tr></table></figure><p>在这段代码中可能需要解释的主要是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.set_grad_enabled(phase == <span class="hljs-string">&#x27;train&#x27;</span>):<br></code></pre></td></tr></table></figure><p>上述代码是用于控制是否计算和存储梯度。这个语句是一个上下文管理器，它会根据参数 <code>mode</code> 来启用或禁用梯度计算。</p><p>这种做法常见于机器学习模型的训练和验证阶段。在训练阶段，我们需要计算梯度以更新模型的参数；而在验证阶段，我们通常不需要计算梯度，因此可以禁用梯度计算以节省内存。</p><p>其他的地方无非就是计算损失<code>criterion(outputs, labels)</code>、计算梯度<code>loss.backward()</code>、更新参数<code>optimizer.step()</code>。记得在开始的时候清空梯度<code>optimizer.zero_grad()</code>。</p><h3 id="Start-Predict"><a href="#Start-Predict" class="headerlink" title="Start Predict"></a>Start Predict</h3><p>经过刚才的步骤会得到一个<code>model.pth</code>这个文件，接下来我们将预测单个模型，下述代码的前部分是预测，后半部分是可视化，有关预测和可视化的地方也没什么好说了，看一看就能明白。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>model = AlexNet()<br>model.load_state_dict(torch.load(<span class="hljs-string">&quot;model.pth&quot;</span>))<br>model.<span class="hljs-built_in">eval</span>()<br><br>image = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;test_data/cat1.jpg&quot;</span>)<br><br>preprocess = transforms.Compose([<br>    transforms.Resize(<span class="hljs-number">256</span>),<br>    transforms.CenterCrop(<span class="hljs-number">224</span>),<br>    transforms.ToTensor(),<br>    transforms.Normalize(mean=[<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], std=[<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>]),<br>])<br>input_tensor = preprocess(image)<br>input_batch = input_tensor.unsqueeze(<span class="hljs-number">0</span>)<br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    output = model(input_batch)<br><br>probabilities = F.softmax(output, dim=<span class="hljs-number">1</span>)<br><br>fig, axs = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>))<br><br>axs[<span class="hljs-number">0</span>].imshow(image)<br>axs[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">&#x27;Original Image&#x27;</span>)<br><br>labels = [<span class="hljs-string">&#x27;Cat&#x27;</span>, <span class="hljs-string">&#x27;Dog&#x27;</span>]<br>axs[<span class="hljs-number">1</span>].bar(labels, probabilities.detach().numpy().flatten())<br>axs[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">&#x27;Probabilities Histogram&#x27;</span>)<br><br>plt.savefig(<span class="hljs-string">&quot;reuslt.png&quot;</span>)<br></code></pre></td></tr></table></figure><p>最后的效果：<br><img src="/../pic/AlexNet/AlexNet3.png" alt="Alt text"><br>这里训练的比较少，效果也只能说将就，至少看起来还是有点像样子的。</p><center>——————到这里就完成了——————</center><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>按照上面的步骤不出意外应该是没有问题的，很适合很久没看或者是新手用来复习和学习，也算是给我之前的学习做一个小总结。</p><p>希望能帮助到你，有问题可以联系邮箱：<a href="mailto:&#106;&#x69;&#97;&#x68;&#x68;&#104;&#x61;&#111;&#x40;&#111;&#x75;&#x74;&#x6c;&#x6f;&#111;&#x6b;&#46;&#99;&#x6f;&#109;">&#106;&#x69;&#97;&#x68;&#x68;&#104;&#x61;&#111;&#x40;&#111;&#x75;&#x74;&#x6c;&#x6f;&#111;&#x6b;&#46;&#99;&#x6f;&#109;</a>，或者在关于中用其他的联系方式，我会尽快回复你，当然如果问题网上能查到最好自己解决~</p>]]></content>
    
    
    <categories>
      
      <category>Computer Vision</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CV</tag>
      
      <tag>AlexNet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>西江月·世事短如春梦</title>
    <link href="/2023/10/31/%E8%A5%BF%E6%B1%9F%E6%9C%88%C2%B7%E4%B8%96%E4%BA%8B%E7%9F%AD%E5%A6%82%E6%98%A5%E6%A2%A6/"/>
    <url>/2023/10/31/%E8%A5%BF%E6%B1%9F%E6%9C%88%C2%B7%E4%B8%96%E4%BA%8B%E7%9F%AD%E5%A6%82%E6%98%A5%E6%A2%A6/</url>
    
    <content type="html"><![CDATA[<h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><center> 西江月·世事短如春梦 </center><br /><center>朱敦儒〔宋代〕</center><br /><center>世事短如春梦，人情薄似秋云。不须计较苦劳心，万事原来有命。</center>　　<center><font color=IndianRed>幸遇三杯酒好，况逢一朵花新。</font>片时欢笑且相亲，明日阴晴未定。</center><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p>　　西江月：原为唐教坊曲，后用作词调。《乐章集》《张子野词》并入“中吕宫”。五十字，上下片各两平韵，结句各叶一仄韵。</p><p>　　计较：算计。</p><p>　　且：姑且，聊且。</p><p>　　相亲：互相亲爱。</p><hr><h2 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h2><p>　　世事短暂，如春梦一般转瞬即逝。人情淡薄，就如秋天朗空上的薄云。不要计较自己的辛勤劳苦，万事本来已命中注定。</p><p>　　有幸遇到三杯美酒，又邂逅了一朵含苞初放的鲜花。短暂的欢乐相聚是如此的亲切，至于明天会怎么样谁也不知道了。</p><hr><h2 id="赏析"><a href="#赏析" class="headerlink" title="赏析"></a>赏析</h2><p>　　这首小词从慨叹人生短暂入笔，表现了词人暮年对世情的一种“彻悟”。</p><p>　　回首平生，少年的欢情，壮年的襟抱早已成为遥远的过去，飞逝的岁月在这位年迈的词人心中留下的只有世态炎凉命途多舛的凄黯记忆。所以词的起首二句“世事短如春梦，人情薄似秋云”，是饱含辛酸的笔触。这两句属对工畅，集中地、形象地表达了作者对人生的认识。“短如春梦”、“薄似秋云”的比喻熨帖而自然。接下来，笔锋一转，把世事人情的种种变化与表现归结为“命”（命运）的力量。“原来”二字，透露出一种无可如何的神情，又隐含几分激愤。在强大的命运之神面前他感到无能为力，于是消极地放弃了抗争:“不须计较苦劳心”，语气间含有对自己早年追求的悔意和自嘲。这两句倒装，不只是为了照顾押韵，也有把意思的重点落在下句的因素。情调由沉重到轻松，也反映了他从顿悟中得到解脱的心情。</p><p>　　似乎是从宿命的解释中真的得到了解脱，词人转而及时行乐，沉迷于美酒鲜花之中“幸遇三杯美酒，况逢一朵花新”，使本词转灰暗向光明、化伤悲为可喜。人之一生虽然有充满变量且难以掌握的“命”存在，但仍有己力能够操控者，譬如：面对美酒，可以独自小酌，也可偕友对饮；而目睹一朵清新可爱、初初绽放的小花，也足以兴发美感，使身心愉悦。此处词人所拣取之“酒”与“花”（“酒”、“花”，在朱词出现的频率颇高，例如：“携酒提篮，……索共梅花笑”（〈点绛唇〉）；“落帽酒中有趣，……花影阑干人静”（〈西江月〉）；“酥点梅花瘦。金杯酒”（〈点绛唇〉）……等等）颇耐人寻味，因为酒代表纵放恣肆，而花则关涉宁静自得，在深谙世事人情的无奈后，心灵自由放松了，这两种不同的生命情境便能兼而有之。朱敦儒这种通过达命而产生的欢喜态度，后出的张孝祥（一一三三～一一七○）领会亦深，因此填有“世路如今已惯，此心到处悠然。寒光亭下水连天，飞起沙鸥一片”。</p><p>　　上下文都是议论，使得这属对工巧的两句尤其显得清新有趣。着墨不多，主人公那种得乐且乐的生活情态活脱脱地展现出来。结语两句，虽以“片时欢笑且相亲”自安自慰，然而至于“明日阴晴未定”，则又是天道无常，陷入更深的叹息中了。“且”是“姑且”、“聊且”的意思。“阴晴未定是感叹世事的翻覆无定，或许还有政治上的寓意。下片末句与上片“万事原来有命”呼应，又回到“命”上去了。作者的生活态度是强作达观而实则颓唐。</p><p>　　起首二句是饱含辛酸的笔触，形象地表达了作者对人生的认识。接下来，笔锋一转，把世事人情的种种变化与表现归结为“命”的力量。结语两句，则又是天道无常，陷入更深的叹息。这首词对仗工整，比喻熨贴而自然，自然流转，若不经意，全词如骏马注坡，一气直下，上下文的议论，亦使得对应句尤其清新有趣</p><hr><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>　　从诗人的角度看来人间世事短、人情薄，而且万事有命这种躺平的态度也挺适合现在社会；不如及时行乐，好酒、鲜花，与朋友的相聚已经足够打发今日，至于明天怎样，谁又管得着呢。</p><p>　　古代的躺平态度在现在浮躁的社会有时候能起到作用，客观的来讲还是需要分门别类，毕竟有时候我还是希望自己能努力努力去更好的地方，有自己想完成的事。</p><p>　　不过这首诗闲暇时光来看还是非常不错的！</p><hr><p>资料来自网站: <a href="https://so.gushiwen.cn/shiwenv_68b2bf1dbf8b.aspx">https://so.gushiwen.cn/shiwenv_68b2bf1dbf8b.aspx</a></p>]]></content>
    
    
    <categories>
      
      <category>Poem</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Poem</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记录一些好用的网站</title>
    <link href="/2023/10/30/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99/"/>
    <url>/2023/10/30/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99/</url>
    
    <content type="html"><![CDATA[<h3 id="英语往年试题的网站"><a href="#英语往年试题的网站" class="headerlink" title="英语往年试题的网站"></a>英语往年试题的网站</h3><p><a href="https://pan.uvooc.com/Learn/CET/CET6">https://pan.uvooc.com/Learn/CET/CET6</a></p><hr><h3 id="SCI-Hub论文下载可用网址链接-实时更新"><a href="#SCI-Hub论文下载可用网址链接-实时更新" class="headerlink" title="SCI-Hub论文下载可用网址链接 - 实时更新"></a>SCI-Hub论文下载可用网址链接 - 实时更新</h3><p><a href="https://tool.yovisun.com/scihub/">https://tool.yovisun.com/scihub/</a></p><hr><h3 id="读论文工具"><a href="#读论文工具" class="headerlink" title="读论文工具"></a>读论文工具</h3><p><a href="https://readpaper.com/">https://readpaper.com/</a></p><hr><h3 id="电子书下载网站"><a href="#电子书下载网站" class="headerlink" title="电子书下载网站"></a>电子书下载网站</h3><p><a href="https://zh.annas-archive.org/">https://zh.annas-archive.org/</a></p><p>配上文件转化器（转PDF等）</p><p><a href="https://convertio.co/zh/">https://convertio.co/zh/</a></p><hr>]]></content>
    
    
    <categories>
      
      <category>Tools &amp;&amp; Website</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CET</tag>
      
      <tag>Paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/10/29/hello-world/"/>
    <url>/2023/10/29/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
